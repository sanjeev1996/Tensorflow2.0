{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeev1996/Tensorflow2.0/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-hSS_nuzTzn",
        "colab_type": "code",
        "outputId": "495b771f-46f3-4e7b-8f00-e9b678f4af19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323,
          "referenced_widgets": [
            "2f1884b0cfe04d1195e61faccf99cace",
            "32b4a5fd0753447e8467a3612b8b8fac",
            "c3a2955e15ba45708fbeb39509fa29c2",
            "e4ece7031716489f9b6cc083ef03eae3"
          ]
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week1()\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from common.download_utils import download_week1_resources\n",
        "\n",
        "download_week1_resources()\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-12 10:12:21--  https://raw.githubusercontent.com/hse-aml/natural-language-processing/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2330 (2.3K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   2.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-12 10:12:21 (33.9 MB/s) - ‘setup_google_colab.py’ saved [2330/2330]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f1884b0cfe04d1195e61faccf99cace",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=7196138), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32b4a5fd0753447e8467a3612b8b8fac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2166270), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3a2955e15ba45708fbeb39509fa29c2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=1041379), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ece7031716489f9b6cc083ef03eae3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5091), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eojoGbba0TPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from ast import literal_eval\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def read_data(filename):\n",
        "    data = pd.read_csv(filename, sep='\\t')\n",
        "    data['tags'] = data['tags'].apply(literal_eval)\n",
        "    return data\n",
        "\n",
        "train = read_data('data/train.tsv')\n",
        "validation = read_data('data/validation.tsv')\n",
        "test = pd.read_csv('data/test.tsv', sep='\\t')\n",
        "\n",
        "X_train, y_train = train['title'].values, train['tags'].values\n",
        "X_val, y_val = validation['title'].values, validation['tags'].values\n",
        "X_test = test['title'].values\n",
        "\n",
        "\n",
        "import re \n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def text_prepare(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower()# lowercase text\n",
        "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = re.sub(BAD_SYMBOLS_RE, \"\", text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = \" \" + text + \" \"\n",
        "    for sw in STOPWORDS:\n",
        "        text = text.replace(\" \"+sw+\" \", \" \") # delete stopwors from text\n",
        "    text = re.sub('[ ][ ]+', \" \", text)\n",
        "    if text[0] == ' ':\n",
        "        text = text[1:]\n",
        "    if text[-1] == ' ':\n",
        "        text = text[:-1]\n",
        "        \n",
        "    return text\n",
        "\n",
        "def test_text_prepare():\n",
        "    examples = [\"SQL Server - any equivalent of Excel's CHOOSE function?\",\n",
        "                \"How to free c++ memory vector<int> * arr?\"]\n",
        "    answers = [\"sql server equivalent excels choose function\", \n",
        "               \"free c++ memory vectorint arr\"]\n",
        "    for ex, ans in zip(examples, answers):\n",
        "        if text_prepare(ex) != ans:\n",
        "            return \"Wrong answer for the case: '%s'\" % ex\n",
        "    return 'Basic tests are passed.'\n",
        "\n",
        "\n",
        "prepared_questions = []\n",
        "for line in open('data/text_prepare_tests.tsv', encoding='utf-8'):\n",
        "    line = text_prepare(line.strip())\n",
        "    prepared_questions.append(line)  \n",
        "text_prepare_results = '\\n'.join(prepared_questions)\n",
        "\n",
        "\n",
        "\n",
        "X_train = [text_prepare(x) for x in X_train]\n",
        "X_val = [text_prepare(x) for x in X_val]\n",
        "X_test = [text_prepare(x) for x in X_ testtest]\n",
        "\n",
        "\n",
        "\n",
        "test\n",
        "from collections import Counter\n",
        "# Dictionary of all tags from train corpus with their counts.\n",
        "tags_counts = Counter()\n",
        "# Dictionary of all words from train corpus with their counts.\n",
        "words_counts = Counter()\n",
        "\n",
        "for words in X_train:\n",
        "    for word in words.split():\n",
        "        words_counts[word] += 1\n",
        "\n",
        "for tags in y_train:\n",
        "    for tag in tags:\n",
        "        tags_counts[tag] += 1\n",
        "         \n",
        "DICT_SIZE = 5000        \n",
        "most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]\n",
        "\n",
        "\n",
        "WORDS_TO_INDEX = {p[0]:i for i,p in enumerate(most_common_words[:DICT_SIZE])}####### YOUR CODE HERE #######\n",
        "INDEX_TO_WORDS = {WORDS_TO_INDEX[k]:k for k in WORDS_TO_INDEX}####### YOUR CODE HERE #######\n",
        "ALL_WORDS = WORDS_TO_INDEX.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoHF0yzEhJ-l",
        "colab_type": "code",
        "outputId": "b484f103-3c5d-4414-84db-6b5518e3ae5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def my_bag_of_words(text, words_to_index, dict_size):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        dict_size: size of the dictionary\n",
        "        \n",
        "        return a vector which is a bag-of-words representation of 'text'\n",
        "    \"\"\"\n",
        "    result_vector = np.zeros(dict_size)\n",
        "    for word in text.split():\n",
        "        if word in words_to_index:\n",
        "            result_vector[words_to_index[word]] += 1\n",
        "    return result_vector\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic tests are passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txTk4xrdk6m_",
        "colab_type": "code",
        "outputId": "0ca65439-8963-466b-cbc3-4978aaaa126f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from scipy import sparse as sp_sparse\n",
        "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
        "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
        "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
        "print('X_train shape ', X_train_mybag.shape)\n",
        "print('X_val shape ', X_val_mybag.shape)\n",
        "print('X_test shape ', X_test_mybag.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape  (100000, 5000)\n",
            "X_val shape  (30000, 5000)\n",
            "X_test shape  (20000, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvbgf2S7nfSP",
        "colab_type": "code",
        "outputId": "9338e3fe-df27-4e1b-9dcd-823e0e3a7f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "print(X_train_mybag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 98)\t1.0\n",
            "  (0, 605)\t1.0\n",
            "  (0, 2854)\t1.0\n",
            "  (1, 13)\t1.0\n",
            "  (1, 36)\t1.0\n",
            "  (1, 84)\t1.0\n",
            "  (1, 116)\t1.0\n",
            "  (1, 292)\t1.0\n",
            "  (1, 599)\t1.0\n",
            "  (1, 645)\t1.0\n",
            "  (1, 1142)\t1.0\n",
            "  (2, 52)\t1.0\n",
            "  (2, 70)\t1.0\n",
            "  (2, 496)\t1.0\n",
            "  (2, 1401)\t1.0\n",
            "  (2, 2119)\t1.0\n",
            "  (3, 6)\t1.0\n",
            "  (3, 12)\t1.0\n",
            "  (3, 59)\t1.0\n",
            "  (3, 135)\t1.0\n",
            "  (3, 167)\t1.0\n",
            "  (3, 190)\t1.0\n",
            "  (3, 1962)\t1.0\n",
            "  (4, 17)\t1.0\n",
            "  (4, 428)\t1.0\n",
            "  :\t:\n",
            "  (99996, 260)\t1.0\n",
            "  (99996, 741)\t1.0\n",
            "  (99996, 1658)\t1.0\n",
            "  (99997, 8)\t1.0\n",
            "  (99997, 278)\t1.0\n",
            "  (99997, 894)\t1.0\n",
            "  (99997, 1050)\t1.0\n",
            "  (99997, 2967)\t1.0\n",
            "  (99997, 3376)\t1.0\n",
            "  (99997, 4747)\t1.0\n",
            "  (99998, 6)\t1.0\n",
            "  (99998, 59)\t1.0\n",
            "  (99998, 175)\t1.0\n",
            "  (99998, 225)\t1.0\n",
            "  (99998, 312)\t1.0\n",
            "  (99998, 427)\t1.0\n",
            "  (99998, 526)\t1.0\n",
            "  (99998, 753)\t1.0\n",
            "  (99998, 875)\t1.0\n",
            "  (99998, 1740)\t1.0\n",
            "  (99998, 3248)\t1.0\n",
            "  (99999, 19)\t1.0\n",
            "  (99999, 27)\t1.0\n",
            "  (99999, 196)\t1.0\n",
            "  (99999, 2085)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UL00TS6xaUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "row = X_train_mybag[10].toarray()[0]\n",
        "non_zero_elements_count = np.count_nonzero(row) ####### YOUR CODE HERE #######\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXCa0PTAxkqa",
        "colab_type": "code",
        "outputId": "7cd84299-f832-416b-b4af-4f5ee30b8da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(non_zero_elements_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 15)\t2.0\n",
            "  (0, 16)\t1.0\n",
            "  (0, 29)\t1.0\n",
            "  (0, 51)\t1.0\n",
            "  (0, 3095)\t1.0\n",
            "  (0, 3326)\t1.0\n",
            "  (0, 4553)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir5-dTvzB0o0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_features(X_train, X_val, X_test):    \n",
        "    tfidf_vectorizer = TfidfVectorizer(token_pattern='(\\S+)', min_df=5, max_df=0.9, ngram_range=(1,2))####### YOUR CODE HERE #######\n",
        "    tfidf_vectorizer.fit(X_train)\n",
        "    \n",
        "    X_train = tfidf_vectorizer.transform(X_train)\n",
        "    X_val = tfidf_vectorizer.transform(X_val)\n",
        "    X_test = tfidf_vectorizer.transform(X_test)\n",
        "    \n",
        "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FZZ7QWFDP1X",
        "colab_type": "code",
        "outputId": "a522ea0b-47f8-405c-ffe6-1882a5045a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('c++' in tfidf_vocab)\n",
        "print('c#' in tfidf_vocab)\n",
        "print('java' in tfidf_vocab)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn5eLT6sZq3R",
        "colab_type": "code",
        "outputId": "243d439b-3418-47e8-e34e-19f614d4b0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tfidf_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HGvX7Lrb3UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei-7nLgUb4Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
        "y_train = mlb.fit_transform(y_train)\n",
        "y_val = mlb.fit_transform(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvRlM6eGb61g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP1H9hzPb-8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier(X_train, y_train, C=1.0, penalty='l2'):\n",
        "    \"\"\"\n",
        "      X_train, y_train — training data\n",
        "      \n",
        "      return: trained classifier\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create and fit LogisticRegression wraped into OneVsRestClassifier.\n",
        "\n",
        "\n",
        "    ######################################\n",
        "    ######### YOUR CODE HERE #############\n",
        "    ######################################    \n",
        "    \n",
        "    lr = LogisticRegression(C=C, penalty=penalty)\n",
        "    \n",
        "    ovr = OneVsRestClassifier(lr)\n",
        "    ovr.fit(X_train, y_train)\n",
        "    return ovr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n_1vWNpcN4t",
        "colab_type": "code",
        "outputId": "659e7fb1-5108-4780-bc1d-198630b470b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "classifier_mybag = train_classifier(X_train_mybag, y_train)\n",
        "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gfNcIFcVxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
        "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
        "\n",
        "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
        "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EQmiMbgceKw",
        "colab_type": "code",
        "outputId": "52a5a0fa-a96a-47af-fef9-c1222052734e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_mybag)\n",
        "y_val_inversed = mlb.inverse_transform(y_val)\n",
        "for i in range(3):\n",
        "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
        "        X_val[i],\n",
        "        ','.join(y_val_inversed[i]),\n",
        "        ','.join(y_val_pred_inversed[i])\n",
        "    ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title:\todbc_exec always fail\n",
            "True labels:\tphp,sql\n",
            "Predicted labels:\t\n",
            "\n",
            "\n",
            "Title:\taccess base classes variable within child class\n",
            "True labels:\tjavascript\n",
            "Predicted labels:\t\n",
            "\n",
            "\n",
            "Title:\tcontenttype application json required rails\n",
            "True labels:\truby,ruby-on-rails\n",
            "Predicted labels:\truby-on-rails\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}