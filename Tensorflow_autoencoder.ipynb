{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow-autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPm/dXA4TOY7o3nvn0MuGTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeev1996/Tensorflow2.0/blob/master/Tensorflow_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXz27TtALUT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ycWlsLONEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dacc2f94-ca77-403a-af2a-050b0508401a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from __future__ import absolute_import, division, print_function\n",
        "print(tf.__version__)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KllRL6KQOm-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST Dataset parameters.\n",
        "num_features = 784 # data features (img shape: 28*28).\n",
        "\n",
        "# Training parameters.\n",
        "learning_rate = 0.01\n",
        "training_steps = 20000\n",
        "batch_size = 256\n",
        "display_step = 1000\n",
        "\n",
        "# Network Parameters\n",
        "num_hidden_1 = 128 # 1st layer num features.\n",
        "num_hidden_2 = 64 # 2nd layer num features (the latent dim)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAqhsnPPTwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare MNIST data.\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Convert to float32.\n",
        "x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n",
        "# Flatten images to 1-D vector of 784 features (28*28).\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "# Normalize images value from [0, 255] to [0, 1].\n",
        "x_train, x_test = x_train / 255., x_test / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPBY6iVTTxd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf.data API to shuffle and batch data.\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(10000).batch(batch_size).prefetch(1)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_data = test_data.repeat().batch(batch_size).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vde17OJWZUFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store layers weight & bias\n",
        "\n",
        "# A random value generator to initialize weights.\n",
        "random_normal = tf.initializers.RandomNormal()\n",
        "\n",
        "weights = {\n",
        "    'encoder_h1': tf.Variable(random_normal([num_features, num_hidden_1])),\n",
        "    'encoder_h2': tf.Variable(random_normal([num_hidden_1, num_hidden_2])),\n",
        "    'decoder_h1': tf.Variable(random_normal([num_hidden_2, num_hidden_1])),\n",
        "    'decoder_h2': tf.Variable(random_normal([num_hidden_1, num_features])),\n",
        "}\n",
        "biases = {\n",
        "    'encoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
        "    'encoder_b2': tf.Variable(random_normal([num_hidden_2])),\n",
        "    'decoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
        "    'decoder_b2': tf.Variable(random_normal([num_features])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkt3OTvzVeQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abac61a5-5ad0-483d-8b8b-e63d26a556ff"
      },
      "source": [
        "weights['encoder_h1'].shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([784, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlohc4iPfnze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder.\n",
        "def encoder(x):\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    return layer_2\n",
        "\n",
        "\n",
        "# Building the decoder.\n",
        "def decoder(x):\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bHolkAh-Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean square loss between original images and reconstructed ones.\n",
        "def mean_square(reconstructed, original):\n",
        "    return tf.reduce_mean(tf.pow(original - reconstructed, 2))\n",
        "\n",
        "# Adam optimizer.\n",
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt3VBoCbjWn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization process. \n",
        "def run_optimization(x):\n",
        "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
        "    with tf.GradientTape() as g:\n",
        "        reconstructed_image = decoder(encoder(x))\n",
        "        loss = mean_square(reconstructed_image, x)\n",
        "\n",
        "    # Variables to update, i.e. trainable variables.\n",
        "    trainable_variables = weights.values() + biases.values()\n",
        "    \n",
        "    # Compute gradients.\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # Update W and b following gradients.\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPyX9D5u9N0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "618fab37-69ae-4f79-9600-9d8f3b4780bd"
      },
      "source": [
        "# Run training for the given number of steps.\n",
        "for step, (batch_x, _) in enumerate(train_data.take(training_steps + 1)):\n",
        "    \n",
        "    # Run the optimization.\n",
        "    loss = run_optimization(batch_x)\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        print(\"step: %i, loss: %f\" % (step, loss))\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-75e4354883f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Run the optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-9719b27967e4>\u001b[0m in \u001b[0;36mrun_optimization\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Variables to update, i.e. trainable variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Compute gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict_values' and 'dict_values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEE6VHXW95WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "n = 4\n",
        "canvas_orig = np.empty((28*n, 28*n))\n",
        "canvas_recon = np.empty((28*n, 28*n))\n",
        "for i, (batch_x, _) in enumerate(text_data.take(n)):\n",
        "  # Encoded and decode the digit image\n",
        "  reconstructeda_images = decoder(encoder(batch_x))\n",
        "  # Display original image\n",
        "  for j in range(n):\n",
        "    # Draw the generated digits\n",
        "    img = batch_x[j].numpy().reshape([28, 28])\n",
        "    canvas_orig[i*28:(i+1)*28, j*28:(j+1)*28] = img\n",
        "  # Display reconstructed image\n",
        "  for j in range(n):\n",
        "    # Draw the generated digits\n",
        "    reconstr_img = reconstructed_images[j].numpy().reshape([28, 28])\n",
        "    canvas_recon[i*28:(i+1)*28, j*28:(j+1)*28] = reconstr_img"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}