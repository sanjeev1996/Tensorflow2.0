{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow-autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSzj2yB8dFNGsPcdtA8IVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeev1996/Tensorflow2.0/blob/master/Tensorflow_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXz27TtALUT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ycWlsLONEb",
        "colab_type": "code",
        "outputId": "c81e567f-7c52-4f68-b5dc-24ec80355df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from __future__ import absolute_import, division, print_function\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KllRL6KQOm-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST Dataset parameters.\n",
        "num_features = 784 # data features (img shape: 28*28).\n",
        "\n",
        "# Training parameters.\n",
        "learning_rate = 0.01\n",
        "training_steps = 20000\n",
        "batch_size = 256\n",
        "display_step = 1000\n",
        "\n",
        "# Network Parameters\n",
        "num_hidden_1 = 128 # 1st layer num features.\n",
        "num_hidden_2 = 64 # 2nd layer num features (the latent dim)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAqhsnPPTwN",
        "colab_type": "code",
        "outputId": "dc8670a3-a1b9-42d4-c127-8b6bbd0297e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prepare MNIST data.\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Convert to float32.\n",
        "x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n",
        "# Flatten images to 1-D vector of 784 features (28*28).\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "# Normalize images value from [0, 255] to [0, 1].\n",
        "x_train, x_test = x_train / 255., x_test / 255."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPBY6iVTTxd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf.data API to shuffle and batch data.\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(10000).batch(batch_size).prefetch(1)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_data = test_data.repeat().batch(batch_size).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vde17OJWZUFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store layers weight & bias\n",
        "\n",
        "# A random value generator to initialize weights.\n",
        "random_normal = tf.initializers.RandomNormal()\n",
        "\n",
        "weights = {\n",
        "    'encoder_h1': tf.Variable(random_normal([num_features, num_hidden_1])),\n",
        "    'encoder_h2': tf.Variable(random_normal([num_hidden_1, num_hidden_2])),\n",
        "    'decoder_h1': tf.Variable(random_normal([num_hidden_2, num_hidden_1])),\n",
        "    'decoder_h2': tf.Variable(random_normal([num_hidden_1, num_features])),\n",
        "}\n",
        "biases = {\n",
        "    'encoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
        "    'encoder_b2': tf.Variable(random_normal([num_hidden_2])),\n",
        "    'decoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
        "    'decoder_b2': tf.Variable(random_normal([num_features])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkt3OTvzVeQy",
        "colab_type": "code",
        "outputId": "6b72c96a-6e02-4a87-e1d7-ec37608d1fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights['encoder_h1'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([784, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlohc4iPfnze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder.\n",
        "def encoder(x):\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    return layer_2\n",
        "\n",
        "\n",
        "# Building the decoder.\n",
        "def decoder(x):\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bHolkAh-Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean square loss between original images and reconstructed ones.\n",
        "def mean_square(reconstructed, original):\n",
        "    return tf.reduce_mean(tf.pow(original - reconstructed, 2))\n",
        "\n",
        "# Adam optimizer.\n",
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt3VBoCbjWn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization process. \n",
        "def run_optimization(x):\n",
        "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
        "    with tf.GradientTape() as g:\n",
        "        reconstructed_image = decoder(encoder(x))\n",
        "        loss = mean_square(reconstructed_image, x)\n",
        "\n",
        "    # Variables to update, i.e. trainable variables.\n",
        "    trainable_variables = list(weights.values()) + list(biases.values())\n",
        "    \n",
        "    # Compute gradients.\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # Update W and b following gradients.\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPyX9D5u9N0D",
        "colab_type": "code",
        "outputId": "04004d82-f98e-4fda-82b8-c08052d78e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Run training for the given number of steps.\n",
        "for step, (batch_x, _) in enumerate(train_data.take(training_steps + 1)):\n",
        "\n",
        "    \n",
        "    loss = run_optimization(batch_x)\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        print(\"step: %i, loss: %f\" % (step, loss))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 0, loss: 0.003723\n",
            "step: 1000, loss: 0.003460\n",
            "step: 2000, loss: 0.003238\n",
            "step: 3000, loss: 0.003386\n",
            "step: 4000, loss: 0.003455\n",
            "step: 5000, loss: 0.003438\n",
            "step: 6000, loss: 0.003364\n",
            "step: 7000, loss: 0.003247\n",
            "step: 8000, loss: 0.003502\n",
            "step: 9000, loss: 0.003351\n",
            "step: 10000, loss: 0.003617\n",
            "step: 11000, loss: 0.003228\n",
            "step: 12000, loss: 0.003094\n",
            "step: 13000, loss: 0.003446\n",
            "step: 14000, loss: 0.003002\n",
            "step: 15000, loss: 0.002981\n",
            "step: 16000, loss: 0.003150\n",
            "step: 17000, loss: 0.003087\n",
            "step: 18000, loss: 0.003154\n",
            "step: 19000, loss: 0.003205\n",
            "step: 20000, loss: 0.003296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEE6VHXW95WC",
        "colab_type": "code",
        "outputId": "160cf7ca-6c5c-4e05-a58a-d1f343d58187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "# Encode and decode images from test set and visualize their reconstruction.\n",
        "import matplotlib.pyplot as plt\n",
        "n = 1\n",
        "canvas_orig = np.empty((28 * n, 28 * n))\n",
        "canvas_recon = np.empty((28 * n, 28 * n))\n",
        "for i, (batch_x, _) in enumerate(test_data.take(n)):\n",
        "    # Encode and decode the digit image.\n",
        "    reconstructed_images = decoder(encoder(batch_x))\n",
        "    # Display original images.\n",
        "    for j in range(n):\n",
        "        # Draw the generated digits.\n",
        "        img = batch_x[j].numpy().reshape([28, 28])\n",
        "        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = img\n",
        "    # Display reconstructed images.\n",
        "    for j in range(n):\n",
        "        # Draw the generated digits.\n",
        "        reconstr_img = reconstructed_images[j].numpy().reshape([28, 28])\n",
        "        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = reconstr_img\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Reconstructed Images\")\n",
        "#plt.figure(figsize=(n, n))\n",
        "#plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0V6P6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Image After layer 1 Encoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-aef3ac266a63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Encode and decode the digit image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mreconstructed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Display original images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-3670f64df245>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image After layer 1 Encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2677\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (128,) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF4AAABZCAYAAAC315PWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAADz0lEQVR4nO2dP4gcZRiHn5+Jf+AKBb1CNBDFkCOF\nhVnUUhAhsbgUWphGI5FrDNaChZDOShCCckiINhpNdYIggoWNf7IHIsagnIJ4IniJkkaIHPwsdqJ7\n693OB/luX3fufWBgZ+Zl5r2HvZ2d2d98I9skk+eG6AZ2Kik+iBQfRIoPIsUHkeKDaBUv6bSk3yR9\ns8V6SXpN0oqkryU9UL/N7lHyjj8DHBqz/jCwr5kWgNevv63u0yre9qfA72NKjgBve8DnwG2S7qzV\nYFfZXWEbdwE/D82vNst+HS2UtMDgv4KZmZmDc3NzFXb//2J5efmS7dm2uhrii7G9CCwC9Ho99/v9\nSe5+Ikj6qaSuxreaX4A9Q/N3N8uSMdQQvwQ83Xy7eRi4Yvs/HzPJRlo/aiS9AzwC3CFpFXgZuBHA\n9hvAh8DjwArwJ/DsdjXbJVrF2z7ast7A89U62iHkmWsQKT6IFB9Eig8ixQeR4oNI8UGk+CBSfBAp\nPogUH0SKDyLFB5Hig0jxQaT4IFJ8ECk+iCLxkg5J+q6J6b24yfpjktYkfdVMz9VvtVuU/Ni9CzgF\nPMYgrHRe0pLtb0dKz9o+sQ09dpKSd/yDwIrtH23/BbzLILaXXAcl4reK6I3yRJMWPidpzybrkyFq\nHVw/APbavh/4GHhrsyJJC5L6kvpra2uVdj2dlIhvjejZvmz7ajP7JnBwsw3ZXrTds92bnW3NdXaa\nEvHngX2S7pF0E/AUg9jeP4zEsueBi/Va7CYlSbJ1SSeAj4BdwGnbFySdBPq2l4AXJM0D6wyy9Me2\nsedOoKg7uzsc01623WuryzPXIFJ8ECk+iBQfRIoPIsUHkeKDSPFBpPggUnwQKT6IFB9Eig8ixQeR\n4oNI8UGk+CBSfBApPoha2cmbJZ1t1n8haW/tRrtGybiT17KTh4EDwFFJB0bKjgN/2L4PeBV4pXaj\nXaNWdvII/6bHzgGPSlK9NrtHySh8m2UnH9qqpsnhXAFuBy4NFw0Pfwhc3Wr01ilnf0lR2PCHkvol\n+ZNpQ1JRWKhKdnK4RtJu4FbgckkDO5Uq2clm/pnm9ZPAJ86Hj4zHduvEYHjD74EfgJeaZSeB+eb1\nLcD7DIZA/BK4t2CbCyX7nrap9O8Ky07udPLMNYgUH0SI+LZLENNI25MlRpm4+MJLENPIGcY/WWID\nEe/4Tt6+WfBkiQ1EiC+9fbPT5ME1iAjx+YQFYsSXXILoPBMXb3sduHb75kXgPdsXJt1HbZonS3wG\n7Je0Kun42Pq8ZBBDHlyDSPFBpPggUnwQKT6IFB9Eig/ib+VEBK5N8h1NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uttx-rcTXifH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder.\n",
        "def encoder(x):\n",
        "\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    print(\"Original Images\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(x[0].numpy().reshape([28, 28]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    \n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    #print(\"Encoder layer_1\")\n",
        "    #plt.figure(figsize=(n, n))\n",
        "    #plt.imshow(layer_1, origin=\"upper\", cmap=\"gray\")\n",
        "\n",
        "    print(\"Image After layer 1 Encoder\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_1[0].numpy(), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()    \n",
        "    \n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    print(\"Image After layer 2 Encoder\")\n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_2[0].numpy().reshape([8, 8]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    return layer_2\n",
        "\n",
        "\n",
        "# Building the decoder.\n",
        "def decoder(x):\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    print(\"Image After layer 1 Decoder\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_1[0].numpy().reshape([16, 8]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show() \n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    print(\"Image After layer 2 Decoder\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_2[0].numpy().reshape([28, 28]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}