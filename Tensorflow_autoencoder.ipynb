{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow-autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDr2TXyphD1L0TbXwWnjak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeev1996/Tensorflow2.0/blob/master/Tensorflow_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXz27TtALUT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ycWlsLONEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c81e567f-7c52-4f68-b5dc-24ec80355df0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from __future__ import absolute_import, division, print_function\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KllRL6KQOm-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST Dataset parameters.\n",
        "num_features = 784 # data features (img shape: 28*28).\n",
        "\n",
        "# Training parameters.\n",
        "learning_rate = 0.01\n",
        "training_steps = 20000\n",
        "batch_size = 256\n",
        "display_step = 1000\n",
        "\n",
        "# Network Parameters\n",
        "num_hidden_1 = 128 # 1st layer num features.\n",
        "num_hidden_2 = 64 # 2nd layer num features (the latent dim)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uAqhsnPPTwN",
        "colab_type": "code",
        "outputId": "dc8670a3-a1b9-42d4-c127-8b6bbd0297e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prepare MNIST data.\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# Convert to float32.\n",
        "x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n",
        "# Flatten images to 1-D vector of 784 features (28*28).\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "# Normalize images value from [0, 255] to [0, 1].\n",
        "x_train, x_test = x_train / 255., x_test / 255."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPBY6iVTTxd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf.data API to shuffle and batch data.\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(10000).batch(batch_size).prefetch(1)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_data = test_data.repeat().batch(batch_size).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vde17OJWZUFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store layers weight & bias\n",
        "\n",
        "# A random value generator to initialize weights.\n",
        "random_normal = tf.initializers.RandomNormal()\n",
        "\n",
        "weights = {\n",
        "    'encoder_h1': tf.Variable(random_normal([num_features, num_hidden_1])),\n",
        "    'encoder_h2': tf.Variable(random_normal([num_hidden_1, num_hidden_2])),\n",
        "    'decoder_h1': tf.Variable(random_normal([num_hidden_2, num_hidden_1])),\n",
        "    'decoder_h2': tf.Variable(random_normal([num_hidden_1, num_features])),\n",
        "}\n",
        "biases = {\n",
        "    'encoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
        "    'encoder_b2': tf.Variable(random_normal([num_hidden_2])),\n",
        "    'decoder_b1': tf.Variable(random_normal([num_hidden_1])),\n",
        "    'decoder_b2': tf.Variable(random_normal([num_features])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkt3OTvzVeQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b72c96a-6e02-4a87-e1d7-ec37608d1fc4"
      },
      "source": [
        "weights['encoder_h1'].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([784, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlohc4iPfnze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder.\n",
        "def encoder(x):\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    return layer_2\n",
        "\n",
        "\n",
        "# Building the decoder.\n",
        "def decoder(x):\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1bHolkAh-Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean square loss between original images and reconstructed ones.\n",
        "def mean_square(reconstructed, original):\n",
        "    return tf.reduce_mean(tf.pow(original - reconstructed, 2))\n",
        "\n",
        "# Adam optimizer.\n",
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt3VBoCbjWn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization process. \n",
        "def run_optimization(x):\n",
        "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
        "    with tf.GradientTape() as g:\n",
        "        reconstructed_image = decoder(encoder(x))\n",
        "        loss = mean_square(reconstructed_image, x)\n",
        "\n",
        "    # Variables to update, i.e. trainable variables.\n",
        "    trainable_variables = list(weights.values()) + list(biases.values())\n",
        "    \n",
        "    # Compute gradients.\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # Update W and b following gradients.\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPyX9D5u9N0D",
        "colab_type": "code",
        "outputId": "04004d82-f98e-4fda-82b8-c08052d78e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Run training for the given number of steps.\n",
        "for step, (batch_x, _) in enumerate(train_data.take(training_steps + 1)):\n",
        "\n",
        "    \n",
        "    loss = run_optimization(batch_x)\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        print(\"step: %i, loss: %f\" % (step, loss))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 0, loss: 0.003723\n",
            "step: 1000, loss: 0.003460\n",
            "step: 2000, loss: 0.003238\n",
            "step: 3000, loss: 0.003386\n",
            "step: 4000, loss: 0.003455\n",
            "step: 5000, loss: 0.003438\n",
            "step: 6000, loss: 0.003364\n",
            "step: 7000, loss: 0.003247\n",
            "step: 8000, loss: 0.003502\n",
            "step: 9000, loss: 0.003351\n",
            "step: 10000, loss: 0.003617\n",
            "step: 11000, loss: 0.003228\n",
            "step: 12000, loss: 0.003094\n",
            "step: 13000, loss: 0.003446\n",
            "step: 14000, loss: 0.003002\n",
            "step: 15000, loss: 0.002981\n",
            "step: 16000, loss: 0.003150\n",
            "step: 17000, loss: 0.003087\n",
            "step: 18000, loss: 0.003154\n",
            "step: 19000, loss: 0.003205\n",
            "step: 20000, loss: 0.003296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEE6VHXW95WC",
        "colab_type": "code",
        "outputId": "5d3f2a64-0ada-4d73-a817-075db8b5c7ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "# Encode and decode images from test set and visualize their reconstruction.\n",
        "import matplotlib.pyplot as plt\n",
        "n = 1\n",
        "canvas_orig = np.empty((28 * n, 28 * n))\n",
        "canvas_recon = np.empty((28 * n, 28 * n))\n",
        "for i, (batch_x, _) in enumerate(test_data.take(n)):\n",
        "    # Encode and decode the digit image.\n",
        "    reconstructed_images = decoder(encoder(batch_x))\n",
        "    # Display original images.\n",
        "    for j in range(n):\n",
        "        # Draw the generated digits.\n",
        "        img = batch_x[j].numpy().reshape([28, 28])\n",
        "        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = img\n",
        "    # Display reconstructed images.\n",
        "    for j in range(n):\n",
        "        # Draw the generated digits.\n",
        "        reconstr_img = reconstructed_images[j].numpy().reshape([28, 28])\n",
        "        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = reconstr_img\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Reconstructed Images\")\n",
        "#plt.figure(figsize=(n, n))\n",
        "#plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
        "#plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0V6P6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Image After layer 1 Encoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD0AAABYCAYAAABGW/8AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOK4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Image After layer 2 Encoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFIAAABWCAYAAABcvcGNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAEgklEQVR4nO2cT0hjVxTGv9PU8V8aXEyq0pbSQjd1\n0Y2MCl3YRcuIC8FVd4KIq+4Vd+LGhZsuuhnGgiAyCCEgMtYWXBREIRYsbbWFNKR0omALolGiknq6\nMDM47T3JU89Nk+b8QDT3u+fdy+e9ee/dd94lZoZxd175rzvwf8GMVMKMVMKMVMKMVMKMVOLVIJWI\n6CGAzwGEADxm5uli9SORCEejUaeWzWbFuIaGBlG7uLhwlodCITHm8PBQ1BobG0VNOmY2m0UulyOX\nVtJIIgoB+ALAxwCeAUgQ0RIz70gx0WgU09Nur9fW1sS2Ojo6RC2dTjvLW1paxJhYLHartqRjLi4u\nijFBpvYDAElmTjHzBYAnAAYCxNUUQYx8A8Dv1z4/K5QZ11A72RDRKBFtEdHW8fGx1mGrhiBGZgC8\nde3zm4Wyl2DmR8zcycydkUhEq39VQxAjEwDeI6J3iOgegE8BLPntVvVR8qzNzHki+gzAKq4uf75k\n5p+KxZycnGB9fd2pHR0diXFLS/L/J5fLOcsHBwfFmGIzY35+XtRmZ2ed5cvLy2JMoOtIZn4K4GmQ\nurWK3dkoYUYqYUYqYUYqYUYqEeisfVPa2towPj7u1FZXV8W43d1dURseHnaWF1vhSSQSora/vy9q\nGxsbzvLT01MxxkakEmakEmakEmakEmakEmakEuQj96e9vZ2HhoacWnNzsxjX398valNTU87yYis8\nra2topbP50VNWmmKxWI4ODhwPvyyEamEGamEGamEGamEGamEl0ULIkJdXZ1T6+npEeNmZmZETVow\nKHY8Kc0FADY3N0VNeq4knc0BG5FqmJFKmJFKmJFKmJFKmJFKBM3YTQPIAvgLQJ6ZO4vVPzs7QzKZ\ndGoDA3JqZW9vr6ilUilneTgcFmP29vZELZP5Vx7YC8bGxpzlExMTYsxNriM/YuY/b1C/prCprURQ\nIxnA10T0HRGN+uxQtRJ0an/IzBkieh3AN0T0MzN/e71CweBRAGhqalLuZuUTaEQyc6bw+wBAHFcJ\n+v+s8yJjt76+XreXVUBJI4momYhee/43gE8A/Oi7Y9VGkKndCiBORM/rLzDzV8UCwuEwuru7ndrC\nwoIY19fXJ2rb29vO8pWVFTFmZGRE1HZ2xNeEbpWyEiT1OQXgg1L1ah27/FHCjFTCjFTCjFTCjFTC\ny8Ov8/NzcbWmq6tLjCv2vvbk5KSzvNhLTnNzc6IWj8dFTbpsury8FGNsRCphRiphRiphRiphRiph\nRirhJWOXiP4A8Fvh430AlfCsR6MfbzOzcx8eL0a+1ADRVqmnjuXAdz9saithRipRDiMflaGNIHjt\nh/fvyFrBprYS3owkoodE9AsRJYnI/fJ2mSCiNBH9QETbRLTlpRFmVv/B1f5AvwJ4F8A9AN8DeN9H\nWwH7kwZw32cbvkZkze3w58vIStvhz3vukpcV8gqkZO7SXfE1IgPt8FcuguQu3RVfRlbMDn/lyl3y\nMrVvs8OfR26cu3Qb7M5GCbuzUcKMVMKMVMKMVMKMVMKMVMKMVMKMVOJvevJHt1eQEbwAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Image After layer 1 Decoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD0AAABYCAYAAABGW/8AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAF1UlEQVR4nO2bXWgUVxTHf2eVRYllaTHRkqxtg6EY\n4weo9atKoLUqgvVFaPQhDwWfAj744pP4IgR8UQSVKFoQkoJCbAjaJkRKBONHCq01NcYkpNYl6SZo\noiAxiZ4+ZHOdu2aTze5mop35wzL/2f/MnXM45869cz9EVfEaAjNtwEzAd9or8J32CnynpwoR2SYi\nD0SkXUQOZsqo6Yak2k6LyCygDdgCPAbuACWq+lfmzJsezE7j3i+AdlXtBBCRH4FvgYROi4gGAqPJ\nNWfOHEubN2+e4YODg5b2/Plzw7Ozsy3NWU4wGDQ8Go0yMDAg49mRjtO5wD+O88fA2oluCAQCzJ07\nF4ClS5da2saNGw1vbW21tIaGBsNLSkosbcmSJYaHw2HD9+/fn9COdJxOCiKyD9gX49P9uKSQjtMR\nIOw4z4v9Z0FVK4AKgFAopGMRLS0tta67fv264fHpffToUcPjs6CgoMDwqqoqw/v7+xMans7b+w5Q\nICKfiUgQ+A6oSaM815BypFV1RETKgF+AWcA5VW3JmGXTiLTqtKpeAa5kyBbXMO0vMify8vIoLy8H\n4PDhw5bmbLKKi4st7cCBA4bv2LHD0u7evWt4NBo1fHh4OKEdfjfUK3A1vQcHB2lrawNg2bJllnbt\n2jXD8/LyLO3ChQuGHzlyxNLWrn3TH1qzZo3hzc3NCe3wZKR9p70CV+t0IBAwX0U3b960tL179xp+\n48YNSwuFQoafPHnS0q5evWr4kydPDB8aGkpsxxRs/t/Ak067mt79/f3U1tYCsHv3bks7fvy44b29\nvZaWn58/7nUAu3btMryystJwP73j4DvtFbhap1XV1LVbt25ZmnO0pLCw0NIuXrxo+NatWy3t8uXL\nhm/atMlw59dXPDwZaU867Wp6Z2VlmS+h+/fvW5rza+n169eWdv78ecPHBiHGsG7dOsPr6uoMf/bs\nWUI7PBlpTzqd8lxWKgiFQrphwwbg7bfwypUrDY9P4ZcvXxq+fv16S+vs7DS8qKjI8FOnThGJRMad\nXfBkpH2nvQJXm6zh4WF6enoAuHTpkqU9evTIcOdAIMDp06cN3759u6Xl5OQYfuzYMcNHRkYS2jFp\npEXknIhEReSe47+PRKReRB7Gjh9OVs67hGTS+wdgW9x/B4EGVS0AGmLn7w2SarJE5FOgVlWLYucP\ngGJV7RaRj4FfVfXzJMoxDzt06JClRSJvZnmd068Ay5cvN9w5UACwefNmw5uamgyvqamhr68vo03W\nAlXtjvEeYEGK5cwI0n6Rqao6IxgP50qEdwWpRvrfWFoTO0YTXaiqFaq6WlVXp/isjCPVSNcApUB5\n7PhTMjetWrXKzDHt2bPH0pzdy4GBAUs7c+aM4Tt37rS0xsZGw511v76+PqEdyTRZVUAT8LmIPBaR\n7xl1douIPAS+jp2/N5g00qpakkD6KsO2uAZXe2QtLS1m3Vd7e7ulOce0nKsSAF69emW486sKMOPo\nAN3d3Yb7gwhx8J32Clyt08FgkEWLFgGwYsUKS+vo6DA8vmu8ePFiw7u6uizt6dOnVvljmGhJpicj\n7UmnXU3vcDjMiRMnAKiurrY059Rqbm6upTkX0zmneADKysoMd6Z0/EoHJzwZad9pr8DVOv3ixQtu\n374NwNmzZy1t4cKFhsePqjhXFDmbJbAnApwjLvHXOeHJSHvSaVfnskSkF/gbmA/0pVncZGV8oqrZ\n4wmuOm0eKtKc7vBROmV4Mr19p11ExUyWMSN1eqbhp/d0IxP7rUWkS0T+FJHfRSTxRo2JoKqu/Bjd\npdcB5ANB4A+gMIVyuoD56djiZqTNfmtVHQLG9lu7DjedHm+/dW6CayeCAnUi8ltscnDKcPUrK0P4\nUlUjIpID1ItIq6o2TnqXA25GOqn91pNBVSOxYxSoZrTaTAluOp32fmsRyRKRD8Y48A1wb+K73oZr\n6Z2h/dYLgOrYAOBsoFJVf56qLX6PzCvwnfYKfKe9At9pr8CTTv8Ho952PaW2lnkAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Image After layer 2 Decoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uttx-rcTXifH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder.\n",
        "def encoder(x):\n",
        "\n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    print(\"Original Images\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(x[0].numpy().reshape([28, 28]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    \n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    #print(\"Encoder layer_1\")\n",
        "    #plt.figure(figsize=(n, n))\n",
        "    #plt.imshow(layer_1, origin=\"upper\", cmap=\"gray\")\n",
        "\n",
        "    print(\"Image After layer 1 Encoder\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_1[0].numpy().reshape([16, 8]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()    \n",
        "    \n",
        "    # Encoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    print(\"Image After layer 2 Encoder\")\n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_2[0].numpy().reshape([8, 8]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    return layer_2\n",
        "\n",
        "\n",
        "# Building the decoder.\n",
        "def decoder(x):\n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    print(\"Image After layer 1 Decoder\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_1[0].numpy().reshape([16, 8]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show() \n",
        "    # Decoder Hidden layer with sigmoid activation.\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    print(\"Image After layer 2 Decoder\")     \n",
        "    plt.figure(figsize=(n, n))\n",
        "    plt.imshow(layer_2[0].numpy().reshape([28, 28]), origin=\"upper\", cmap=\"gray\")\n",
        "    plt.show()\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}